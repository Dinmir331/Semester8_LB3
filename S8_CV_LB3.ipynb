{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUjL4OMt1euHFXwsNyK5uB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dinmir331/Semester8_LB3/blob/main/S8_CV_LB3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 лаба -- Дано видео, нужно его считать (на видео бегает мыш по полу), отделить мышь от пола и найти её центр на каждом кадре видеоряда используя код разумеется, а не покадровое разбиение с указанием где центр вручную.\n",
        "\n",
        "\n",
        "1. **Вычитание фона** — выделение мыши через медианное усреднение кадров и морфологию.  \n",
        "2. **Трекинг** — отслеживание объекта методом корреляции шаблонов с адаптацией.  \n",
        "3. **Обработка кадров** — бинаризация, морфология, фильтрация контуров по площади/пропорциям.  \n",
        "4. **Визуализация** — отрисовка bounding box, центра и траектории в GIF.  \n",
        "5. **Пакетная обработка** — автоматическая обработка 10 видео с выводом статистики."
      ],
      "metadata": {
        "id": "KH62_qqOW-9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Импорт необходимых библиотек"
      ],
      "metadata": {
        "id": "Iy6Y6IM8lzVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np                  # Для работы с массивами и математическими операциями\n",
        "import cv2                          # Основная библиотека для компьютерного зрения\n",
        "import imageio                      # Для создания GIF-анимаций\n",
        "from google.colab import drive      # Для подключения Google Drive\n",
        "\n",
        "# Монтируем Google Drive для доступа к файлам\n",
        "drive.mount('/content/drive', force_remount=True)  # Подключение облачного хранилища Google Drive"
      ],
      "metadata": {
        "id": "2YeN8jYG7EvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8908335-991a-462b-b182-c9adcc85a1bc"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Инициализия видеопотка и возврат параметров видео"
      ],
      "metadata": {
        "id": "7LtuLg7-7L32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_video(video_path):\n",
        "    # Открываем видеофайл с помощью OpenCV\n",
        "    cap = cv2.VideoCapture(video_path)  # Создаем объект захвата видео\n",
        "    if not cap.isOpened():  # Проверка, удалось ли открыть видео\n",
        "        raise ValueError(f\"Ошибка открытия видео: {video_path}\")  # Выбрасываем ошибку, если видео не открыто\n",
        "\n",
        "    # Определяем исходное разрешение видео (ширина и высота)\n",
        "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # Получаем ширину кадра\n",
        "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # Получаем высоту кадра\n",
        "\n",
        "    return cap, original_width, original_height  # Возвращаем объект захвата и размеры кадра"
      ],
      "metadata": {
        "id": "DpXMHkmr7Dgl"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение вычитателя фона на начальных кадрах"
      ],
      "metadata": {
        "id": "TvVR7snl7U7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_static_background(cap, initial_frames, learning_rate, median_blur, morph_iterations):\n",
        "    ret, frame = cap.read()  # Читаем первый кадр видео\n",
        "\n",
        "    # Сбор кадров для медианного усреднения\n",
        "    buffer = []  # Создаем список для хранения обработанных кадров\n",
        "    for _ in range(initial_frames):  # Проходим по первым initial_frames кадрам\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Преобразуем кадр в градации серого\n",
        "        gray = cv2.medianBlur(gray, median_blur)  # Применяем медианное размытие для уменьшения шума\n",
        "        buffer.append(gray)  # Добавляем обработанный кадр в буфер\n",
        "        ret, frame = cap.read()  # Читаем следующий кадр\n",
        "        if not ret:  # Если кадры закончились, прерываем цикл\n",
        "            break\n",
        "\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Сбрасываем позицию чтения кадров к началу видео\n",
        "\n",
        "    # Вычисление медианного фона\n",
        "    background = np.median(buffer, axis=0).astype(np.uint8)  # Вычисляем медиану всех кадров в буфере\n",
        "\n",
        "    # Улучшение фона с помощью морфологических операций\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))  # Создаем эллиптическое ядро для морфологии\n",
        "    background = cv2.morphologyEx(background, cv2.MORPH_CLOSE, kernel, iterations=morph_iterations)  # Закрываем мелкие дыры\n",
        "\n",
        "    return background  # Возвращаем модель фона"
      ],
      "metadata": {
        "id": "LiuTR4U57CQt"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Создание трекера"
      ],
      "metadata": {
        "id": "q6ivU4w37geG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def csrt_tracking(frame, roi, tracker_state=None):\n",
        "    \"\"\"\n",
        "    Реализация CSRT-подобного трекинга через корреляцию шаблонов\n",
        "    :param frame: Текущий кадр\n",
        "    :param roi: ROI-область в формате (x, y, w, h)\n",
        "    :param tracker_state: Состояние трекера (для сохранения шаблона)\n",
        "    :return: Новый bbox, состояние трекера, статус успеха\n",
        "    \"\"\"\n",
        "\n",
        "    if tracker_state is None:  # Если трекер еще не инициализирован\n",
        "        # Инициализация трекера\n",
        "        x, y, w, h = roi  # Распаковываем координаты и размеры ROI\n",
        "        template = frame[y:y+h, x:x+w]  # Вырезаем область интереса (ROI) из кадра\n",
        "        template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)  # Преобразуем ROI в градации серого\n",
        "        template_gray = cv2.GaussianBlur(template_gray, (7, 7), 0)  # Применяем Гауссово размытие для уменьшения шума\n",
        "        return {'template': template_gray}, (x, y, w, h), True  # Возвращаем шаблон и координаты ROI\n",
        "\n",
        "    # Обновление трекера\n",
        "    template = tracker_state['template']  # Получаем текущий шаблон из состояния трекера\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Преобразуем текущий кадр в градации серого\n",
        "    frame_gray = cv2.GaussianBlur(frame_gray, (7, 7), 0)  # Применяем Гауссово размытие для уменьшения шума\n",
        "\n",
        "    # Поиск совпадений методом корреляции\n",
        "    result = cv2.matchTemplate(frame_gray, template, cv2.TM_CCOEFF_NORMED)  # Ищем совпадения шаблона в кадре\n",
        "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)  # Находим максимальное значение корреляции\n",
        "\n",
        "    if max_val < 0.5:  # Если корреляция ниже порога, считаем, что объект потерян\n",
        "        return None, None, False  # Возвращаем статус неудачи\n",
        "\n",
        "    # Вычисление новых координат объекта\n",
        "    h_template, w_template = template.shape[:2]  # Получаем размеры шаблона\n",
        "    x, y = max_loc  # Координаты максимального совпадения\n",
        "    new_bbox = (x, y, w_template, h_template)  # Формируем новый bounding box\n",
        "\n",
        "    # Обновление шаблона каждые 5 кадров\n",
        "    if np.random.randint(5) == 0:  # Случайно выбираем момент для обновления шаблона\n",
        "        new_template = frame[y:y+h_template, x:x+w_template]  # Вырезаем новую область интереса\n",
        "        new_template_gray = cv2.cvtColor(new_template, cv2.COLOR_BGR2GRAY)  # Преобразуем в градации серого\n",
        "        new_template_gray = cv2.GaussianBlur(new_template_gray, (7, 7), 0)  # Применяем Гауссово размытие\n",
        "        tracker_state['template'] = new_template_gray  # Обновляем шаблон в состоянии трекера\n",
        "\n",
        "    return tracker_state, new_bbox, True  # Возвращаем обновленное состояние, новый bbox и статус успеха"
      ],
      "metadata": {
        "id": "2ubSMp6Y7AYF"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обработка кадров для поиска объекта"
      ],
      "metadata": {
        "id": "RKe_AhBI7ok9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_frame(frame, background, var_threshold, min_area, max_aspect_ratio):\n",
        "    # Преобразование текущего кадра в градации серого для упрощения обработки\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Преобразуем BGR-изображение в градации серого\n",
        "\n",
        "    # Вычисление маски движения путем вычитания фона\n",
        "    fgmask = cv2.absdiff(gray_frame, background)  # Находим абсолютную разницу между текущим кадром и фоном\n",
        "    _, fgmask = cv2.threshold(fgmask, var_threshold, 255, cv2.THRESH_BINARY)  # Бинаризация разницы (выделяем движущиеся области)\n",
        "\n",
        "    # Применение Гауссова размытия для уменьшения шума на изображении\n",
        "    gray = cv2.GaussianBlur(gray_frame, (7, 7), 0)  # Размытие с ядром 7x7 для сглаживания\n",
        "    _, bw_mask = cv2.threshold(gray, 60, 255, cv2.THRESH_BINARY_INV)  # Бинаризация по порогу яркости (инвертированная маска)\n",
        "\n",
        "    # Комбинирование масок для улучшения выделения объекта\n",
        "    combined_mask = cv2.bitwise_and(fgmask, bw_mask)  # Логическое \"И\" между масками движения и яркости\n",
        "\n",
        "    # Морфологические операции для улучшения качества маски\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))  # Создаем эллиптическое ядро размером 9x9\n",
        "    gray = cv2.erode(gray, kernel, iterations=2)  # Эрозия для удаления мелких шумов и затемнения\n",
        "    gray = cv2.dilate(gray, kernel, iterations=2)  # Дилатация для соединения частей объекта и осветления\n",
        "\n",
        "    # Дополнительная обработка комбинированной маски\n",
        "    combined_mask = cv2.bitwise_and(fgmask, bw_mask)  # Повторное комбинирование масок\n",
        "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel, iterations=3)  # Операция \"открытия\" для устранения шума\n",
        "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel, iterations=3)  # Операция \"закрытия\" для заполнения дыр\n",
        "\n",
        "    # Поиск контуров на основе улучшенной маски\n",
        "    contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # Поиск внешних контуров\n",
        "    valid_contours = []  # Список для хранения валидных контуров\n",
        "    for cnt in contours:\n",
        "        area = cv2.contourArea(cnt)  # Вычисляем площадь контура\n",
        "        if area < min_area:  # Фильтруем контуры по минимальной площади (игнорируем маленькие)\n",
        "            continue\n",
        "\n",
        "        # Получаем координаты ограничивающего прямоугольника\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        aspect_ratio = w / h  # Вычисляем соотношение сторон\n",
        "\n",
        "        # Фильтрация по соотношению сторон (исключаем слишком продолговатые или узкие объекты)\n",
        "        if aspect_ratio > max_aspect_ratio or aspect_ratio < 1 / max_aspect_ratio:\n",
        "            continue\n",
        "\n",
        "        valid_contours.append(cnt)  # Добавляем валидный контур в список\n",
        "\n",
        "    mask = combined_mask.astype(np.uint8)  # Преобразуем маску в формат uint8 для дальнейшего использования\n",
        "\n",
        "    return mask, valid_contours  # Возвращаем маску и список валидных контуров"
      ],
      "metadata": {
        "id": "F8y-vnFP6531"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Отрисовка траектории на кадре"
      ],
      "metadata": {
        "id": "9e-RaswH8EoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_trajectory(frame, trajectory, color=(255, 0, 255), thickness=2):\n",
        "    if len(trajectory) > 1:  # Проверяем, есть ли хотя бы две точки для отрисовки линии\n",
        "        pts = np.array(trajectory, np.int32).reshape((-1, 1, 2))  # Преобразуем список точек в массив NumPy\n",
        "        cv2.polylines(frame, [pts], False, color, thickness)  # Рисуем ломаную линию траектории на кадре\n",
        "        # Параметры: frame — исходный кадр, [pts] — массив точек, False — замкнутая линия, color — цвет, thickness — толщина"
      ],
      "metadata": {
        "id": "OFydraiG637N"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Основная функция трекинга мыши\n"
      ],
      "metadata": {
        "id": "7gNQhZdk76JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def track_mouse(video_path, output_gif, mask_gif_path,\n",
        "               var_threshold=10, # Порог чувствительности вычитания фона (меньше = чувствительнее)\n",
        "               detection_interval=8,  # Кадров между полными циклами обнаружения\n",
        "               min_area=10000, # Минимальная площадь объекта для обнаружения (фильтрация шума)\n",
        "               max_aspect_ratio=4.0,  # Максимальное соотношение сторон (фильтрация продолговатых объектов)\n",
        "               scale_factor=0.5, # Коэффициент уменьшения (0.5 = 50% от исходного размера изображения)\n",
        "               frame_rate=30.0,  # Желаемая частота кадров\n",
        "               frame_skip=2 # Частота кадров принимаемых в GIF-анимацию (чем больше — тем быстрее видео)\n",
        "              ):\n",
        "    # Инициализация видеопотока и получение параметров видео\n",
        "    cap, original_width, original_height = initialize_video(video_path)  # Открываем видеофайл\n",
        "    # Получаем реальную частоту кадров исходного видео\n",
        "    real_fps = cap.get(cv2.CAP_PROP_FPS)  # Извлекаем FPS из метаданных видео\n",
        "    if real_fps <= 0:  # Если FPS не удалось получить, используем значение по умолчанию\n",
        "        real_fps = frame_rate\n",
        "\n",
        "    # Расчёт длительности одного кадра в секундах\n",
        "    duration = (1.0 / real_fps)  # Длительность кадра для GIF\n",
        "\n",
        "    # Настройка модели фона\n",
        "    background = calculate_static_background(\n",
        "      cap,\n",
        "      initial_frames=30,  # Используем первые 30 кадров для создания модели фона\n",
        "      learning_rate=0.1,  # Скорость адаптации модели фона\n",
        "      median_blur=7,      # Усиленное медианное размытие для подавления шума\n",
        "      morph_iterations=3  # Итерации морфологических операций для улучшения фона\n",
        "      )\n",
        "\n",
        "    # Переменные состояния\n",
        "    tracker_state = None  # Переменная для хранения состояния трекера\n",
        "    trajectory = []       # Список для хранения координат траектории\n",
        "    frames = []           # Список для хранения обработанных кадров\n",
        "    mask_frames = []      # Список для хранения масок объекта\n",
        "\n",
        "    # Основной цикл обработки видео\n",
        "    while True:\n",
        "        ret, frame = cap.read()  # Чтение следующего кадра\n",
        "        if not ret:  # Если кадры закончились, завершаем цикл\n",
        "            break\n",
        "\n",
        "        # Обработка кадра для выделения движущегося объекта\n",
        "        mask, valid_contours = process_frame(\n",
        "            frame, background, var_threshold, min_area, max_aspect_ratio)  # Вычисление маски и контуров\n",
        "        mask_frames.append(cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR))  # Преобразование маски в RGB для сохранения\n",
        "\n",
        "        # Обработка трекера (если он активен)\n",
        "        if tracker_state is not None:\n",
        "            tracker_state, bbox, success = csrt_tracking(frame, bbox, tracker_state)  # Обновление трекера\n",
        "            if success:  # Если объект успешно найден\n",
        "                x, y, w, h = map(int, bbox)  # Получаем координаты bounding box\n",
        "                cx = x + w // 2             # Центр объекта по оси X\n",
        "                cy = y + h // 2             # Центр объекта по оси Y\n",
        "\n",
        "                SMOOTHING_FACTOR = 0.5      # Коэффициент сглаживания траектории\n",
        "                MAX_SMOOTH_POINTS = 3       # Количество точек для усреднения\n",
        "\n",
        "                # Плавное обновление координат центра объекта\n",
        "                if len(trajectory) >= MAX_SMOOTH_POINTS:\n",
        "                    smooth_cx = int(np.mean([p[0] for p in trajectory[-MAX_SMOOTH_POINTS:]]) * (1 - SMOOTHING_FACTOR) + cx * SMOOTHING_FACTOR)\n",
        "                    smooth_cy = int(np.mean([p[1] for p in trajectory[-MAX_SMOOTH_POINTS:]]) * (1 - SMOOTHING_FACTOR) + cy * SMOOTHING_FACTOR)\n",
        "                    cx, cy = smooth_cx, smooth_cy  # Обновляем координаты с учётом сглаживания\n",
        "\n",
        "                trajectory.append((cx, cy))  # Добавляем новые координаты в траекторию\n",
        "\n",
        "                # Отрисовка трекера на кадре\n",
        "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)  # Рисуем прямоугольник вокруг объекта\n",
        "                cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1)  # Рисуем центр объекта\n",
        "                cv2.putText(frame, \"Tracking\", (x, y - 10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)  # Добавляем текст \"Tracking\"\n",
        "            else:\n",
        "                tracker_state = None  # Сброс трекера при потере объекта\n",
        "\n",
        "        # Периодическое обнаружение объекта\n",
        "        if not tracker_state or len(trajectory) % detection_interval == 0:\n",
        "            if valid_contours:  # Если есть валидные контуры\n",
        "                main_contour = max(valid_contours, key=cv2.contourArea)  # Выбираем контур с максимальной площадью\n",
        "                x, y, w, h = cv2.boundingRect(main_contour)  # Получаем координаты bounding box\n",
        "                tracker_state, bbox, _ = csrt_tracking(frame, (x, y, w, h))  # Инициализация трекера\n",
        "\n",
        "        draw_trajectory(frame, trajectory)  # Отрисовка траектории на кадре\n",
        "        frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))  # Сохраняем обработанный кадр в RGB формате\n",
        "\n",
        "    # Пропуск кадров для оптимизации GIF\n",
        "    frames = frames[::frame_skip]  # Пропускаем кадры согласно frame_skip\n",
        "    mask_frames = mask_frames[::frame_skip]  # Пропускаем кадры масок\n",
        "\n",
        "    # Сохранение результатов в GIF\n",
        "    size = (int(original_width * scale_factor), int(original_height * scale_factor))  # Новый размер кадра\n",
        "    with imageio.get_writer(output_gif, duration=duration, loop=0, subrectangles=True) as writer:\n",
        "        for frame in frames:  # Запись обработанных кадров в GIF\n",
        "            writer.append_data(cv2.resize(frame, size))  # Масштабирование кадра перед записью\n",
        "\n",
        "    with imageio.get_writer(mask_gif_path, duration=duration, loop=0, subrectangles=True) as writer:\n",
        "        for mask in mask_frames:  # Запись масок в GIF\n",
        "            writer.append_data(cv2.resize(mask, size))  # Масштабирование маски перед записью\n",
        "\n",
        "    # Вывод статистики\n",
        "    print(f\"Скорость видео: {real_fps:.1f} FPS, масштаб: {scale_factor}\")\n",
        "    print(f\"Кадров в видео: {len(frames)}, масок: {len(mask_frames)}\")\n",
        "\n",
        "    cap.release()  # Освобождение ресурсов (закрытие видеофайла)\n",
        "    print(f\"Готово! Сохранено: {output_gif} и {mask_gif_path}\")"
      ],
      "metadata": {
        "id": "3jeC5Bag6sKN"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вызов функции"
      ],
      "metadata": {
        "id": "PsnFT3Nn6uaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Базовые пути для обработки видео\n",
        "base_video_path = '/content/drive/MyDrive/Colab Notebooks/LB3_Mouse{}.mp4'  # Шаблон пути к исходным видео\n",
        "base_output_gif = '/content/drive/MyDrive/Colab Notebooks/LB3_Mouse_tracking{}.gif'  # Шаблон пути для сохранения GIF\n",
        "base_mask_gif = '/content/drive/MyDrive/Colab Notebooks/LB3_Mouse_mask{}.gif'  # Шаблон пути для сохранения масок\n",
        "\n",
        "# Цикл обработки нескольких видео\n",
        "for i in range(1, 11):  # Обрабатываем видео с номерами от 1 до 10\n",
        "    video_path = base_video_path.format(i)  # Формируем путь к текущему видео\n",
        "    output_gif = base_output_gif.format(i)  # Формируем путь для сохранения GIF\n",
        "    mask_gif_path = base_mask_gif.format(i)  # Формируем путь для сохранения масок\n",
        "\n",
        "    print(f\"Начинаю обработку видео {i}\")  # Выводим сообщение о начале обработки\n",
        "\n",
        "    try:\n",
        "        track_mouse(\n",
        "            video_path=video_path,  # Путь к исходному видео\n",
        "            output_gif=output_gif,  # Путь для сохранения GIF\n",
        "            mask_gif_path=mask_gif_path  # Путь для сохранения масок\n",
        "        )\n",
        "        print(f\"Успешно завершена обработка видео {i}\\n\")  # Выводим сообщение об успешной обработке\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка при обработке видео {i}: {str(e)}\\n\")  # Выводим сообщение об ошибке"
      ],
      "metadata": {
        "id": "In5em6BS6uUV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17274d95-8ee2-4307-a635-cf1cb5aada51"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Начинаю обработку видео 1\n",
            "Скорость видео: 30.0 FPS, масштаб: 0.5\n",
            "Кадров в видео: 102, масок: 102\n",
            "Готово! Сохранено: /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_tracking1.gif и /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_mask1.gif\n",
            "Успешно завершена обработка видео 1\n",
            "\n",
            "Начинаю обработку видео 2\n",
            "Скорость видео: 29.9 FPS, масштаб: 0.5\n",
            "Кадров в видео: 160, масок: 160\n",
            "Готово! Сохранено: /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_tracking2.gif и /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_mask2.gif\n",
            "Успешно завершена обработка видео 2\n",
            "\n",
            "Начинаю обработку видео 3\n",
            "Скорость видео: 29.9 FPS, масштаб: 0.5\n",
            "Кадров в видео: 151, масок: 151\n",
            "Готово! Сохранено: /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_tracking3.gif и /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_mask3.gif\n",
            "Успешно завершена обработка видео 3\n",
            "\n",
            "Начинаю обработку видео 4\n",
            "Скорость видео: 30.0 FPS, масштаб: 0.5\n",
            "Кадров в видео: 156, масок: 156\n",
            "Готово! Сохранено: /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_tracking4.gif и /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_mask4.gif\n",
            "Успешно завершена обработка видео 4\n",
            "\n",
            "Начинаю обработку видео 5\n",
            "Скорость видео: 30.0 FPS, масштаб: 0.5\n",
            "Кадров в видео: 212, масок: 212\n",
            "Готово! Сохранено: /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_tracking5.gif и /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_mask5.gif\n",
            "Успешно завершена обработка видео 5\n",
            "\n",
            "Начинаю обработку видео 6\n",
            "Скорость видео: 29.8 FPS, масштаб: 0.5\n",
            "Кадров в видео: 164, масок: 164\n",
            "Готово! Сохранено: /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_tracking6.gif и /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_mask6.gif\n",
            "Успешно завершена обработка видео 6\n",
            "\n",
            "Начинаю обработку видео 7\n",
            "Скорость видео: 28.3 FPS, масштаб: 0.5\n",
            "Кадров в видео: 148, масок: 148\n",
            "Готово! Сохранено: /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_tracking7.gif и /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_mask7.gif\n",
            "Успешно завершена обработка видео 7\n",
            "\n",
            "Начинаю обработку видео 8\n",
            "Скорость видео: 58.1 FPS, масштаб: 0.5\n",
            "Кадров в видео: 301, масок: 301\n",
            "Готово! Сохранено: /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_tracking8.gif и /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_mask8.gif\n",
            "Успешно завершена обработка видео 8\n",
            "\n",
            "Начинаю обработку видео 9\n",
            "Скорость видео: 30.0 FPS, масштаб: 0.5\n",
            "Кадров в видео: 181, масок: 181\n",
            "Готово! Сохранено: /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_tracking9.gif и /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_mask9.gif\n",
            "Успешно завершена обработка видео 9\n",
            "\n",
            "Начинаю обработку видео 10\n",
            "Скорость видео: 58.0 FPS, масштаб: 0.5\n",
            "Кадров в видео: 322, масок: 322\n",
            "Готово! Сохранено: /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_tracking10.gif и /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_mask10.gif\n",
            "Успешно завершена обработка видео 10\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Основная функция трекинга мыши mp4"
      ],
      "metadata": {
        "id": "8zVbuRF1HUAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# не учитывать\n",
        "\n",
        "# def track_mouse(video_path, output_mp4, mask_mp4_path,\n",
        "#                var_threshold=10, # Порог чувствительности вычитания фона (меньше = чувствительнее)\n",
        "#                detection_interval=8,  # Кадров между полными циклами обнаружения\n",
        "#                min_area=10000, # Минимальная площадь объекта для обнаружения (фильтрация шума)\n",
        "#                max_aspect_ratio=4.0,  # Максимальное соотношение сторон (фильтрация продолговатых объектов)\n",
        "#                scale_factor=1.0, # Коэффициент уменьшения (0.5 = 50% от исходного размера изображения)\n",
        "#                frame_rate=30.0,  # Желаемая частота кадров\n",
        "#                speed_factor=1.0  # Множитель скорости (0.5 - ускорить в 2 раза, 2 - замедлить)\n",
        "#               ):\n",
        "\n",
        "#     cap, original_width, original_height = initialize_video(video_path) # Открываем видеофайл\n",
        "\n",
        "#     # Настройка вычитателя фона\n",
        "#     background = calculate_static_background(\n",
        "#       cap,\n",
        "#       initial_frames=30,\n",
        "#       learning_rate=0.1,\n",
        "#       median_blur=7,          # Усиленное размытие\n",
        "#       morph_iterations=3      # Больше морфологии\n",
        "#       )\n",
        "\n",
        "#     # Переменные состояния\n",
        "#     tracker_state = None # Переменная для хранения трекера\n",
        "#     trajectory = [] # Хранение координат траектории\n",
        "\n",
        "#     # Получаем реальную частоту кадров исходного видео\n",
        "#     real_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "#     if real_fps <= 0:\n",
        "#         real_fps = frame_rate  # Значение по умолчанию, если не удалось получить\n",
        "\n",
        "#     # Сохранение результатов\n",
        "#     size = (int(original_width*scale_factor), int(original_height*scale_factor))\n",
        "\n",
        "#     # Настройка записи видео\n",
        "#     fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "#     # Расчет целевой частоты кадров\n",
        "#     target_fps = real_fps * speed_factor\n",
        "\n",
        "#     # Основное видео\n",
        "#     out_video = cv2.VideoWriter(\n",
        "#         output_mp4,\n",
        "#         fourcc,\n",
        "#         target_fps,\n",
        "#         size\n",
        "#     )\n",
        "\n",
        "#     # Видео с масками\n",
        "#     out_mask = cv2.VideoWriter(\n",
        "#         mask_mp4_path,\n",
        "#         fourcc,\n",
        "#         target_fps,\n",
        "#         size\n",
        "#     )\n",
        "\n",
        "#     while True:\n",
        "#         ret, frame = cap.read()\n",
        "#         if not ret:\n",
        "#             break\n",
        "\n",
        "#         # Обрабатываем маску на каждом кадре\n",
        "#         mask, valid_contours = process_frame(\n",
        "#             frame, background, var_threshold, min_area, max_aspect_ratio)\n",
        "\n",
        "#         # Обработка трекера\n",
        "#         if tracker_state is not None:\n",
        "#             tracker_state, bbox, success = csrt_tracking(frame, bbox, tracker_state)\n",
        "#             if success:\n",
        "#                 x, y, w, h = map(int, bbox)         # Получаем координаты\n",
        "#                 cx = x + w//2                       # Центр объекта по X\n",
        "#                 cy = y + h//2                       # Центр объекта по Y\n",
        "\n",
        "#                 SMOOTHING_FACTOR = 0.3  # Коэффициент сглаживания (0.0 - максимальное сглаживание, 1.0 - без сглаживания)\n",
        "#                 MAX_SMOOTH_POINTS = 3   # Количество точек для усреднения\n",
        "\n",
        "#                 # Плавное обновление координат\n",
        "#                 if len(trajectory) >= MAX_SMOOTH_POINTS:\n",
        "#                   # Берем среднее из последних MAX_SMOOTH_POINTS точек\n",
        "#                   smooth_cx = int(np.mean([p[0] for p in trajectory[-MAX_SMOOTH_POINTS:]]) * (1 - SMOOTHING_FACTOR) + cx * SMOOTHING_FACTOR)\n",
        "#                   smooth_cy = int(np.mean([p[1] for p in trajectory[-MAX_SMOOTH_POINTS:]]) * (1 - SMOOTHING_FACTOR) + cy * SMOOTHING_FACTOR)\n",
        "#                   cx, cy = smooth_cx, smooth_cy\n",
        "\n",
        "#                 trajectory.append((cx, cy))\n",
        "\n",
        "#                 # Отрисовка трекера\n",
        "#                 cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2) # Прямоугольник вокруг объекта\n",
        "#                 cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1) # Центр объекта\n",
        "#                 cv2.putText(frame, \"Tracking\", (x, y-10),\n",
        "#                             cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "#             else:\n",
        "#                 tracker_state = None # Сброс трекера при потере\n",
        "\n",
        "#         # Периодическое обнаружение объекта\n",
        "#         if not tracker_state or len(trajectory) % detection_interval == 0:\n",
        "#             if valid_contours:\n",
        "#                 main_contour = max(valid_contours, key=cv2.contourArea)\n",
        "#                 x, y, w, h = cv2.boundingRect(main_contour)\n",
        "#                 tracker_state, bbox, _ = csrt_tracking(frame, (x,y,w,h))  # Инициализация\n",
        "\n",
        "#         draw_trajectory(frame, trajectory)\n",
        "\n",
        "#         # Запись кадров вместо сохранения в списки\n",
        "#         resized_frame = cv2.resize(frame, size)\n",
        "#         resized_mask = cv2.resize(cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR), size)\n",
        "\n",
        "#         out_video.write(resized_frame)\n",
        "#         out_mask.write(resized_mask)\n",
        "\n",
        "#     # Освобождение ресурсов\n",
        "#     out_video.release()\n",
        "#     out_mask.release()\n",
        "#     cap.release()\n",
        "\n",
        "#     print(f\"Скорость видео: {real_fps:.1f} FPS, масштаб: {scale_factor}\")\n",
        "\n",
        "#     print(f\"Готово! Сохранено: {output_mp4} и {mask_mp4_path}\")"
      ],
      "metadata": {
        "id": "WphgJW0vGeYB"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вызов функции mp4"
      ],
      "metadata": {
        "id": "JB-Jee5CHazP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# не учитывать\n",
        "\n",
        "# # Базовые пути\n",
        "# base_video_path = '/content/drive/MyDrive/Colab Notebooks/LB3_Mouse{}.mp4' # Путь к исходному видео\n",
        "# base_output_mp4 = '/content/drive/MyDrive/Colab Notebooks/LB3_Mouse_tracking{}.mp4' # Путь для сохранения mp4\n",
        "# base_mask_mp4 = '/content/drive/MyDrive/Colab Notebooks/LB3_Mouse_mask{}.mp4' # Путь для сохранения mp4 бинаризированной маски\n",
        "\n",
        "# # Цикл обработки\n",
        "# for i in range(1, 11):  # От 1 до 10 включительно\n",
        "#     video_path = base_video_path.format(i)\n",
        "#     output_mp4 = base_output_mp4.format(i)\n",
        "#     mask_mp4_path = base_mask_mp4.format(i)\n",
        "\n",
        "#     print(f\"Начинаю обработку видео {i}\")\n",
        "\n",
        "#     try:\n",
        "#         track_mouse(\n",
        "#             video_path=video_path,\n",
        "#             output_mp4=output_mp4,\n",
        "#             mask_mp4_path=mask_mp4_path\n",
        "#         )\n",
        "#         print(f\"Успешно завершена обработка видео {i}\\n\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Ошибка при обработке видео {i}: {str(e)}\\n\")"
      ],
      "metadata": {
        "id": "GhQBQRtbGhYB"
      },
      "execution_count": 93,
      "outputs": []
    }
  ]
}