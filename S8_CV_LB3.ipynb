{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeLxF3tDyEaXHtgCZqnsFG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dinmir331/Semester8_LB3/blob/main/S8_CV_LB3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3 лаба -- Дано видео, нужно его считать (на видео бегает мыш по полу), отделить мышь от пола и найти её центр на каждом кадре видеоряда используя код разумеется, а не покадровое разбиение с указанием где центр вручную.\n"
      ],
      "metadata": {
        "id": "KH62_qqOW-9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Импорт необходимых библиотек"
      ],
      "metadata": {
        "id": "Iy6Y6IM8lzVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np                  # Для работы с массивами и математическими операциями\n",
        "import cv2                          # Основная библиотека для компьютерного зрения\n",
        "import imageio                      # Для создания GIF-анимаций\n",
        "from google.colab import drive      # Для подключения Google Drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True) # Монтируем Google Drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YeN8jYG7EvF",
        "outputId": "061e0f8c-e352-41f6-d4bd-adf4427a40a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Инициализия видеопотка и возврат параметров видео"
      ],
      "metadata": {
        "id": "7LtuLg7-7L32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_video(video_path):\n",
        "\n",
        "    cap = cv2.VideoCapture(video_path) # Открываем видеофайл\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(f\"Ошибка открытия видео: {video_path}\")\n",
        "    # Определяем целевой размер для масштабирования (используется при обработке каждого кадра)\n",
        "    original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    return cap, original_width, original_height"
      ],
      "metadata": {
        "id": "DpXMHkmr7Dgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение вычитателя фона на начальных кадрах"
      ],
      "metadata": {
        "id": "TvVR7snl7U7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_static_background(cap, initial_frames, learning_rate,median_blur,morph_iterations):\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Сбор кадров для медианного усреднения\n",
        "    buffer = []\n",
        "    for _ in range(initial_frames):\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        gray = cv2.medianBlur(gray, median_blur)  # Медианное размытие\n",
        "        buffer.append(gray)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # Сброс к началу\n",
        "\n",
        "    # Вычисление медианного фона\n",
        "    background = np.median(buffer, axis=0).astype(np.uint8)\n",
        "\n",
        "    # Улучшение фона морфологией\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5,5))\n",
        "    background = cv2.morphologyEx(background, cv2.MORPH_CLOSE, kernel, iterations=morph_iterations)\n",
        "\n",
        "    return background"
      ],
      "metadata": {
        "id": "LiuTR4U57CQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Создание трекера"
      ],
      "metadata": {
        "id": "q6ivU4w37geG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def csrt_tracking(frame, roi, tracker_state=None):\n",
        "    \"\"\"\n",
        "    Реализация CSRT-подобного трекинга через корреляцию шаблонов\n",
        "    :param frame: Текущий кадр\n",
        "    :param roi: ROI-область в формате (x,y,w,h)\n",
        "    :param tracker_state: Состояние трекера (для сохранения шаблона)\n",
        "    :return: Новый bbox, состояние трекера, статус успеха\n",
        "    \"\"\"\n",
        "\n",
        "    if tracker_state is None:\n",
        "        # Инициализация трекера\n",
        "        x, y, w, h = roi\n",
        "        template = frame[y:y+h, x:x+w]\n",
        "        template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
        "        template_gray = cv2.GaussianBlur(template_gray, (7,7), 0)\n",
        "        return {'template': template_gray}, (x,y,w,h), True\n",
        "\n",
        "    # Обновление трекера\n",
        "    template = tracker_state['template']\n",
        "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    frame_gray = cv2.GaussianBlur(frame_gray, (7,7), 0)\n",
        "\n",
        "    # Поиск совпадений методом корреляции\n",
        "    result = cv2.matchTemplate(frame_gray, template, cv2.TM_CCOEFF_NORMED)\n",
        "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)\n",
        "\n",
        "    if max_val < 0.5:  # Порог совпадения\n",
        "        return None, None, False\n",
        "\n",
        "    # Вычисление новых координат\n",
        "    h_template, w_template = template.shape[:2]\n",
        "    x, y = max_loc\n",
        "    new_bbox = (x, y, w_template, h_template)\n",
        "\n",
        "    # Обновление шаблона каждые 5 кадров\n",
        "    if np.random.randint(5) == 0:\n",
        "        new_template = frame[y:y+h_template, x:x+w_template]\n",
        "        new_template_gray = cv2.cvtColor(new_template, cv2.COLOR_BGR2GRAY)\n",
        "        new_template_gray = cv2.GaussianBlur(new_template_gray, (7,7), 0)\n",
        "        tracker_state['template'] = new_template_gray\n",
        "\n",
        "\n",
        "\n",
        "    return tracker_state, new_bbox, True"
      ],
      "metadata": {
        "id": "2ubSMp6Y7AYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обработка кадров для поиска объекта"
      ],
      "metadata": {
        "id": "RKe_AhBI7ok9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_frame(frame, background, var_threshold, min_area, max_aspect_ratio):\n",
        "    # Вычисление маски движения\n",
        "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # Преобразование в градации серого\n",
        "    fgmask = cv2.absdiff(gray_frame, background)  # Разница с фоном\n",
        "    _, fgmask = cv2.threshold(fgmask, var_threshold, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    gray = cv2.GaussianBlur(gray_frame, (7,7), 0)  # фильтр Гауссиана для уменьшения шума\n",
        "    _, bw_mask = cv2.threshold(gray, 60, 255, cv2.THRESH_BINARY_INV)\n",
        "    combined_mask = cv2.bitwise_and(fgmask, bw_mask)\n",
        "\n",
        "    # Морфологические операции для улучшения маски\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9)) # Отдельное ядро для предобработки\n",
        "    gray = cv2.erode(gray, kernel, iterations=2)  # Сжатие для удаления мелких  шумов / затемнение\n",
        "    gray = cv2.dilate(gray, kernel, iterations=2)  # Расширение для соединения частей объекта / осветление\n",
        "\n",
        "    combined_mask = cv2.bitwise_and(fgmask, bw_mask)  # Комбинированная маска\n",
        "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel, iterations=3) # Убирает шум\n",
        "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel, iterations=3) # Закрывает дыры\n",
        "\n",
        "    # Поиск и фильтрация контуров\n",
        "    contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    valid_contours = []\n",
        "    for cnt in contours:\n",
        "        area = cv2.contourArea(cnt)\n",
        "        if area < min_area:\n",
        "            continue\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        aspect_ratio = w / h\n",
        "        if aspect_ratio > max_aspect_ratio or aspect_ratio < 1/max_aspect_ratio:\n",
        "            continue\n",
        "        valid_contours.append(cnt)\n",
        "\n",
        "    return combined_mask, valid_contours"
      ],
      "metadata": {
        "id": "F8y-vnFP6531"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Отрисовка траектории на кадре"
      ],
      "metadata": {
        "id": "9e-RaswH8EoN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_trajectory(frame, trajectory, color=(255, 0, 255), thickness=2):\n",
        "    if len(trajectory) > 1:\n",
        "        pts = np.array(trajectory, np.int32).reshape((-1, 1, 2))\n",
        "        cv2.polylines(frame, [pts], False, color, thickness) # Рисуем на оригинальном кадре"
      ],
      "metadata": {
        "id": "OFydraiG637N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Основная функция трекинга мыши\n"
      ],
      "metadata": {
        "id": "7gNQhZdk76JV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def track_mouse(video_path, output_gif, mask_gif_path,\n",
        "               var_threshold=10, # Порог чувствительности вычитания фона (меньше = чувствительнее)\n",
        "               detection_interval=12,  # Кадров между полными циклами обнаружения\n",
        "               min_area=3000, # Минимальная площадь объекта для обнаружения (фильтрация шума)\n",
        "               max_aspect_ratio=4.0,  # Максимальное соотношение сторон (фильтрация продолговатых объектов)\n",
        "               scale_factor=0.25 # Коэффициент уменьшения (0.5 = 50% от исходного размера изображения)\n",
        "              ):\n",
        "\n",
        "    cap, original_width, original_height = initialize_video(video_path) # Открываем видеофайл\n",
        "\n",
        "    # Настройка вычитателя фона\n",
        "    background = calculate_static_background(\n",
        "      cap,\n",
        "      initial_frames=30,\n",
        "      learning_rate=0.1,\n",
        "      median_blur=7,          # Усиленное размытие\n",
        "      morph_iterations=3      # Больше морфологии\n",
        "      )\n",
        "\n",
        "    # Переменные состояния\n",
        "    tracker_state = None # Переменная для хранения трекера\n",
        "    trajectory = [] # Хранение координат траектории\n",
        "    frames = [] # Список для хранения обработанных кадров\n",
        "    mask_frames = [] # список для хранения масок\n",
        "\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Обработка трекера\n",
        "        if tracker_state is not None:\n",
        "            tracker_state, bbox, success = csrt_tracking(frame, bbox, tracker_state)\n",
        "            if success:\n",
        "                x, y, w, h = map(int, bbox)         # Получаем координаты\n",
        "                cx = x + w//2                       # Центр объекта по X\n",
        "                cy = y + h//2                       # Центр объекта по Y\n",
        "\n",
        "                SMOOTHING_FACTOR = 0.3  # Коэффициент сглаживания (0.0 - максимальное сглаживание, 1.0 - без сглаживания)\n",
        "                MAX_SMOOTH_POINTS = 3   # Количество точек для усреднения\n",
        "\n",
        "                # Плавное обновление координат\n",
        "                if len(trajectory) >= MAX_SMOOTH_POINTS:\n",
        "                  # Берем среднее из последних MAX_SMOOTH_POINTS точек\n",
        "                  smooth_cx = int(np.mean([p[0] for p in trajectory[-MAX_SMOOTH_POINTS:]]) * (1 - SMOOTHING_FACTOR) + cx * SMOOTHING_FACTOR)\n",
        "                  smooth_cy = int(np.mean([p[1] for p in trajectory[-MAX_SMOOTH_POINTS:]]) * (1 - SMOOTHING_FACTOR) + cy * SMOOTHING_FACTOR)\n",
        "                  cx, cy = smooth_cx, smooth_cy\n",
        "\n",
        "                trajectory.append((cx, cy))\n",
        "\n",
        "                # Отрисовка трекера\n",
        "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 2) # Прямоугольник вокруг объекта\n",
        "                cv2.circle(frame, (cx, cy), 5, (0, 0, 255), -1) # Центр объекта\n",
        "                cv2.putText(frame, \"Tracking\", (x, y-10),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "            else:\n",
        "                tracker_state = None # Сброс трекера при потере\n",
        "\n",
        "        # Периодическое обнаружение объекта\n",
        "        if not tracker_state or len(trajectory) % detection_interval == 0:\n",
        "            mask, valid_contours = process_frame(frame, background, var_threshold,\n",
        "                                   min_area, max_aspect_ratio)\n",
        "\n",
        "            if valid_contours:\n",
        "                main_contour = max(valid_contours, key=cv2.contourArea)\n",
        "                x, y, w, h = cv2.boundingRect(main_contour)\n",
        "                tracker_state, bbox, _ = csrt_tracking(frame, (x,y,w,h))  # Инициализация\n",
        "\n",
        "        # Сохранение маски и кадра\n",
        "        mask_frames.append(cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)\n",
        "                          if 'mask' in locals() else np.zeros_like(frame))\n",
        "\n",
        "        draw_trajectory(frame, trajectory)\n",
        "        frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # Сохранение результатов\n",
        "    size = (int(original_width*scale_factor), int(original_height*scale_factor))\n",
        "    with imageio.get_writer(output_gif, duration=0.03, loop=0) as writer:\n",
        "        for frame in frames:\n",
        "            writer.append_data(cv2.resize(frame, size)) # Создание GIF\n",
        "\n",
        "    with imageio.get_writer(mask_gif_path, duration=0.03, loop=0) as writer:\n",
        "        for mask in mask_frames:\n",
        "            writer.append_data(cv2.resize(mask, size)) # Сохраняем маски в отдельный GIF\n",
        "\n",
        "    cap.release() # Освобождение ресурсов\n",
        "    print(f\"Готово! Сохранено: {output_gif} и {mask_gif_path}\")"
      ],
      "metadata": {
        "id": "3jeC5Bag6sKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вызов функции"
      ],
      "metadata": {
        "id": "PsnFT3Nn6uaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "track_mouse(\n",
        "    video_path='/content/drive/MyDrive/Colab Notebooks/LB3_Mouse10.mp4', # Путь к исходному видео\n",
        "    output_gif='/content/drive/MyDrive/Colab Notebooks/LB3_Mouse_tracking10.gif', # Путь для сохранения GIF\n",
        "    mask_gif_path='/content/drive/MyDrive/Colab Notebooks/LB3_Mouse_mask10.gif' # Путь для сохранения GIF бинаризированной маски\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In5em6BS6uUV",
        "outputId": "a5812f64-250c-4982-df04-013f742f7ec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Готово! Сохранено: /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_tracking10.gif и /content/drive/MyDrive/Colab Notebooks/LB3_Mouse_mask10.gif\n"
          ]
        }
      ]
    }
  ]
}